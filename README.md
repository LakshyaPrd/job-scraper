# Job Scraper - Full Stack Application

A production-ready job scraping application that aggregates job postings from LinkedIn and Indeed.

## ğŸ—ï¸ Architecture

- **Backend**: FastAPI + Python + MongoDB
- **Frontend**: Next.js + TypeScript + Tailwind CSS
- **Database**: MongoDB
- **Scheduler**: APScheduler for automated scraping

## ğŸ“ Project Structure

```
job-search/
â”œâ”€â”€ app/                          # Backend (FastAPI)
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ linkedin_scraper.py
â”‚   â”‚   â””â”€â”€ indeed_scraper.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ job_service.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ scheduler.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ job-scraper-frontend/         # Frontend (Next.js)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â””â”€â”€ page.tsx
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ JobCard.tsx
â”‚           â”œâ”€â”€ SearchBar.tsx
â”‚           â””â”€â”€ StatsBar.tsx
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+
- MongoDB (local or cloud)

### 1. Start MongoDB

```bash
# Using Docker
docker run -d -p 27017:27017 --name mongodb mongo:latest

# Or install MongoDB locally
```

### 2. Backend Setup

```bash
cd c:\job-search

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start the backend server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

### 3. Frontend Setup

```bash
cd job-scraper-frontend

# Initialize Next.js (first time only)
npx create-next-app@latest . --typescript --tailwind --app --use-npm

# Install dependencies
npm install

# Start development server
npm run dev
```

The frontend will be available at `http://localhost:3000`

## ğŸ”§ Configuration

### Backend (.env)

```env
MONGODB_URL=mongodb://localhost:27017
DATABASE_NAME=job_scraper
CORS_ORIGINS=http://localhost:3000
SCRAPE_INTERVAL_HOURS=6
VERIFY_INTERVAL_HOURS=12
```

### Frontend (.env.local)

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| GET | `/api/jobs` | Get all active jobs |
| POST | `/api/scrape` | Trigger job scraping |
| POST | `/api/search` | Search jobs by role |
| POST | `/api/verify` | Verify job status |

## âœ¨ Features

- **Multi-source scraping**: LinkedIn and Indeed
- **Automatic scheduling**: Configurable scraping intervals
- **Job verification**: Check if listings are still active
- **Real-time search**: Search across all scraped jobs
- **Beautiful UI**: Modern, responsive design with Tailwind CSS
- **New job badges**: Highlight jobs posted in last 24 hours

## ğŸ“ License

MIT
